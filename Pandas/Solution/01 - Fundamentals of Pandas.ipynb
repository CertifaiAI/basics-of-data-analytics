{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "massive-geometry",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "![logo](../../img/license_header_logo.png)\n",
    "> **Copyright &copy; 2021 CertifAI Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program is part of OSRFramework. You can redistribute it and/or modify\n",
    "<br>it under the terms of the GNU Affero General Public License as published by\n",
    "<br>the Free Software Foundation, either version 3 of the License, or\n",
    "<br>(at your option) any later version.\n",
    "<br>\n",
    "<br>This program is distributed in the hope that it will be useful,\n",
    "<br>but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "<br>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "<br>GNU Affero General Public License for more details.\n",
    "<br>\n",
    "<br>You should have received a copy of the GNU Affero General Public License\n",
    "<br>along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-waters",
   "metadata": {},
   "source": [
    "# <a name=\"top\">01 - Fundamentals of `pandas`</a>\n",
    "Authored by: Scotrraaj Gopal - scotrraaj.gopal@certifai.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-perspective",
   "metadata": {},
   "source": [
    "## <a name=\"description\">Notebook Description</a>\n",
    "\n",
    "This series of notebooks is an introduction to the `pandas` module, the most popular Python library for data analysis in a tabular structure. This notebook, in particular, would emphasize on the inception of the two core data objects of `pandas`, which are `Series` and `DataFrame`.\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. Explain about `Series` and `DataFrame` object\n",
    "2. Create the `Series` and `DataFrame` object\n",
    "3. Read data from CSV and JSON\n",
    "4. Write data to CSV and JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-lancaster",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "Here's the outline for this tutorial:\n",
    "1. [Notebook Description](#description)\n",
    "2. [Notebook Configurations](#configuration)\n",
    "3. [Core Components](#core)\n",
    "    - [Series](#series)\n",
    "    - [DataFrame](#dataframe)\n",
    "4. [Reading Data Files](#read)\n",
    "    - [Read from CSV](#read_csv)\n",
    "    - [Read from JSON](#read_json)\n",
    "5. [Writing Data Files](#write)\n",
    "    - [Write to CSV](#write_csv)\n",
    "    - [Write to JSON](#write_json)\n",
    "6. [Summary](#summary)\n",
    "7. [Reference](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-nickel",
   "metadata": {},
   "source": [
    "## <a name=\"configuration\">Notebook Configurations</a>\n",
    "\n",
    "First of all, the `pandas` module has to be imported. Since we'll be using it so much, let's use the common alias `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alpha-bidding",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-826f6d99baefdbd6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a58644",
   "metadata": {},
   "source": [
    "## <a name=\"core\">Core Components</a>\n",
    "\n",
    "The core components of `pandas` are the `Series` and `DataFrame` objects.\n",
    "\n",
    "|  | cats |\n",
    "|-|:-:|\n",
    "| 0 | 3 |\n",
    "| 1 | 7 |\n",
    "| 2 | 1 |\n",
    "| 3 | 0 |\n",
    "\n",
    "<center><i>Series</i></center>\n",
    "\n",
    "|  | cats | dogs |\n",
    "|-|:-:|:-:|\n",
    "| 0 | 3 | 4 |\n",
    "| 1 | 7 | 1 |\n",
    "| 2 | 1 | 6 |\n",
    "| 3 | 0 | 9 |\n",
    "\n",
    "<center><i>DataFrame</i></center>\n",
    "\n",
    "But before we get ahead of ourselves, let's visualize some of the attributes of the data objects so that you will be able to relate to them when creating your data objects.\n",
    "\n",
    "![01-00](../../img/pandas/01-00.png)\n",
    "\n",
    "You should also take note of the data types or `dtypes` in `pandas` as when doing data analysis, it is important to make sure you are using the correct data types; otherwise you may get unexpected results or errors. In `pandas`, most time we will let `pandas` to infer the data type automatically based on the data that we input, but despite that, at some point in your data processing, you will likely need to explicitly convert data types from one type to another.\n",
    "\n",
    "| `pandas` dtypes | Python | Usage |\n",
    "|:-:|:-:|:-:|\n",
    "| object | str or mixed | Text or mixed numeric and <br>non-numeric values |\n",
    "| int64 | int | Integer numbers |\n",
    "| float64 | float | Floating point numbers |\n",
    "| bool | bool | True/False values |\n",
    "| datetime64 | datetime | Date and time values |\n",
    "| timedelta[ns] | NA | Differences between <br>two datetimes |\n",
    "| category | NA | Finite list of text <br>values |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd275b",
   "metadata": {},
   "source": [
    "### <a name=\"series\">Series</a>\n",
    "\n",
    "Essentially a `Series` is a single-column or 1-dimensional data with homogenous data. Homogenous meaning the column contains data with the same data type. For example, the following `Series` is a collection of integers:-\n",
    "\n",
    "|  | cats |\n",
    "|-|:-:|\n",
    "| 0 | 3 |\n",
    "| 1 | 7 |\n",
    "| 2 | 1 |\n",
    "| 3 | 0 |\n",
    "\n",
    "You may create the object with `pd.Series(data, index, dtype, name)` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc7207",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86508d003120641d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Jupyter allows the use of Shift+Tab+Tab shortcut to get hints for the methods.\n",
    "# Tab to autocomplete or get suggestions\n",
    "# IMPORTANT: To know the default values of a method! Some remain \"None\" while some are inferred based on the input.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "series = pd.Series(data=[3,7,1,0], name='cats')\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe887046",
   "metadata": {},
   "source": [
    "In the previous example, you created a `Series` with an array. Also observe that the index for the series was generated automatically, since there was nothing passed into the `index` attribute. The `name` attribute of the series will be the name of the column when multiple series are concatenated when creating a `DataFrame`.\n",
    "\n",
    "Another way to create a `Series` is with Python's `dict`. Do keep in mind that the keys you use with a `dict` in a Series will become the `index` of the row. This is not the same when using `dict` to create a DataFrame. If the `index` attribute was passed along with the `dict`, the index labels will abide to the indexes provided under that attribute. \n",
    "\n",
    "> *Note: Good indexing allows easier data locating. Basic operation like locating data by index is part of the coming notebooks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba0f93",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d0e220c6a28147af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "dict = {'a': 5, 'b':3, 'c':8, 'd':9}\n",
    "series = pd.Series(dict)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0867f",
   "metadata": {},
   "source": [
    "### <a name=\"dataframe\">DataFrame</a>\n",
    "\n",
    "`DataFrame` is a 2-dimensional table and potentially allows heterogenous data. It contains an array of individual entries, each of which has a certain value. Each entry correspond to a *row* and a *column*. :-\n",
    "\n",
    "|  | animals | quantity |\n",
    "|-|:-:|:-:|\n",
    "| 0 | cat | 4 |\n",
    "| 1 | dog | 1 |\n",
    "| 2 | fish | 6 |\n",
    "| 3 | hamster | 9 |\n",
    "\n",
    "You may create the object with `pd.DataFrame(data, index, columns, dtype)` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d362e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf969b77ead5d2e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "dict = {\n",
    "    \"animals\": [\"cat\",\"dog\",\"fish\",\"frog\"],\n",
    "    \"quantity\": [4,1,6,9]\n",
    "}\n",
    "df = pd.DataFrame(data = dict)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2e6b8",
   "metadata": {},
   "source": [
    "In the example above, we used a `dict` object to create the `DataFrame`. Unlike `Series`, when a `dict` is inputted into a `DataFrame` constructor, its keys become the column labels.\n",
    "\n",
    "You can also use `pd.concat` to concatenate two `Series` objects into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336f24e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf0708ce509d3be4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "column1 = pd.Series([\"cat\",\"dog\",\"fish\",\"frog\"], name= \"animals\")\n",
    "column2 = pd.Series([4,1,6,9], name = \"quantity\")\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "df = pd.concat([column1,column2], axis=1)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "print(type(df))\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f66ee",
   "metadata": {},
   "source": [
    "Watch that you'll have to modify the `axis` attribute to explicitly describe **which direction** you want the data to be concatenated. It is advised to master these constructors and understand how their attributes affect the object, before you continue your learning journey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a09b88",
   "metadata": {},
   "source": [
    "## <a name=\"read\">Reading Data Files</a>\n",
    "Being able to create a `Series` or `DataFrame` manually is handy but, most of the time, we won't be doing that. Instead, we will be working with data that already exists. Data can be stored in various form and formats. By far, the most basic of these is the CSV file.\n",
    "\n",
    "### <a name=\"read_csv\">Read from CSV</a>\n",
    "CSV is abbreviated from comma-separated values. So, a CSV file is a table of values separated by commas.\n",
    "\n",
    "Let's use the `pd.read_csv()` method to read a sample file at `../../Datasets/pandas/sample.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4dccf",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d04cd5cb081d4d40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "sample = pd.read_csv(\"../../Datasets/pandas/sample.csv\", index_col=[0])\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46834281",
   "metadata": {},
   "source": [
    "Great! So if you noticed, `pd.read_csv` has so many attributes making it a very powerful and flexible method. The `sep` attribute can be modified to any delimiter that your data file uses. Other common ones include Tabs (`/t`), space (` `) and colons (`:`). This method can also be used for any plain text files in the `.txt` format.\n",
    "\n",
    "Let's try to import data from one of those at `../../Datasets/pandas/sample.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e1197",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6d5d40e6646f691",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "sample = pd.read_csv(\"../../Datasets/pandas/sample.txt\", index_col = 0)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc62b5",
   "metadata": {},
   "source": [
    "Observe that `pandas` provides a great number of options to read data files from various formats. Another common format of storing data is in the form of `.json` files.\n",
    "\n",
    "### <a name=\"read_json\">Read from JSON</a>\n",
    "Big data sets in database systems are often extracted or stored in JSON files. JSON is a plain text file (which is human-readable by the way) and is a popular standard for communicating between client and servers.\n",
    "\n",
    "Let's import the same data but from a file with `.json` extension from `../../Datasets/pandas/sample.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ae5b6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27c369c8b05394c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "sample = pd.read_json(\"../../Datasets/pandas/sample.json\")\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb51a03",
   "metadata": {},
   "source": [
    "Note that when importing a well-formatted `.json` file, the indexes have been inferred correctly without any need to specify in the attributes. You may also supply URLs into the read methods.\n",
    "\n",
    "`pandas` also offers methods to read from binary files which are not human-readable such as `.pkl`. Different read methods have different attributes to them to deal with importing issues that come up when reading data from their respective extensions. Hence, it's a no-brainer to use the right method for the given file format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f532d",
   "metadata": {},
   "source": [
    "## <a name=\"read\">Writing Data Files</a>\n",
    "\n",
    "Lastly, it is of course important to be able to write the data that you have analyzed into your computer. This is really handy in `pandas` as it supports many different data formats by default.\n",
    "\n",
    "### <a name=\"write_csv\">Writing to CSV</a>\n",
    "The most typical output format is the CSV file. One could easily save the data in their `DataFrame` into a CSV using the method `to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f8b3c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-042dc84263376b63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c40530bf03e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m### BEGIN SOLUTION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"output.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\dev-time-series\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_'"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"animals\": [\"cat\",\"dog\",\"fish\",\"frog\"],\n",
    "    \"quantity\": [4,1,6,9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "df.to_csv(\"output.csv\")\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf488f",
   "metadata": {},
   "source": [
    "### <a name=\"write_json\">Write to JSON</a>\n",
    "We can write our data into a JSON file with the `to_json()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac8276",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7d707d2b39bcc963",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"animals\": [\"cat\",\"dog\",\"fish\",\"frog\"],\n",
    "    \"quantity\": [4,1,6,9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "df.to_json(\"output.json\")\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14661d4",
   "metadata": {},
   "source": [
    "##  <a name=\"summary\">Summary</a>\n",
    "To conclude, you should now be able to:\n",
    "1. Explain about `Series` and `DataFrame` object\n",
    "2. Create the `Series` and `DataFrame` object\n",
    "3. Read data from CSV and JSON\n",
    "4. Write data to CSV and JSON\n",
    "\n",
    "Congratulations, that concludes this lesson. In the next lesson, we will explore on the must-know basic functions when doing data analysis with `pandas`. \n",
    "\n",
    "See you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-protection",
   "metadata": {},
   "source": [
    "## <a name=\"reference\">Reference</a>\n",
    "* [Attribute Visualization Source](https://geo-python.github.io/site/notebooks/L5/exploring-data-using-pandas.html)\n",
    "* [Dataset Source](https://www.kaggle.com/zynicide/wine-reviews)\n",
    "\n",
    "<font size=2>[Back to Top](#top)</font>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
